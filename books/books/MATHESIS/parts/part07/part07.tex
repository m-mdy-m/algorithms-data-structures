%----------------------------------------------
\part{Probability Theory: Randomness and Expectation}
\label{part:probability}

\begin{partintro}
\lettrine[lines=3]{P}{robability theory} provides the mathematical framework for reasoning under uncertainty. From randomized algorithms to machine learning, probabilistic thinking permeates modern computation. This part develops probability from measure-theoretic foundations to concentration inequalities and stochastic processes.

\vspace{1em}
\textbf{What Makes This Different:}
\begin{itemize}[noitemsep]
    \item \textbf{Measure-Theoretic Rigor:} Probability as a branch of analysis
    \item \textbf{Concentration Bounds:} Chernoff, Hoeffding, Azuma inequalities
    \item \textbf{Randomized Algorithms:} Probabilistic method and derandomization
    \item \textbf{Stochastic Processes:} Markov chains, martingales, Brownian motion
\end{itemize}

\begin{quote}
\textit{``The theory of probability is at bottom nothing but common sense reduced to calculus.''}

\hfill--- \textsc{Pierre-Simon Laplace}
\end{quote}
\end{partintro}

\chapter{Probability Spaces and Measure Theory}
\chapter{Random Variables and Distributions}
\chapter{Expectation and Linearity}
\chapter{Variance, Covariance, and Correlation}
\chapter{Markov, Chebyshev, and Chernoff Bounds}
\chapter{Limit Theorems: Law of Large Numbers and CLT}
\chapter{Markov Chains and Ergodic Theory}
\chapter{Martingales and Stopping Times}
\chapter{Brownian Motion and Stochastic Calculus}
\chapter{Information Theory and Entropy}
\chapter{Coding Theory and Error Correction}
\chapter{Probabilistic Method in Combinatorics}